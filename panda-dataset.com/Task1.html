<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Task1 | PANDA Dataset</title>
    <link rel="icon" href="https://panda-website-1301093743.cos.ap-hongkong.myqcloud.com/images/logo/label-logo.png" sizes="32x32">
    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/fontello.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="css/animsition.min.css">
    <!-- Google Fonts -->
    <!-- <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700|Merriweather:300,300i,400,400i,700,700i" rel="stylesheet"> -->
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elients and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body class="animsition">
    <div class="header">
        <div class="container">
            <div class="row">
                <div class="col-md-4 col-sm-4 col-xs-6">
                    <!-- logo -->
                    <div class="logo">
                        <a href="index.html"><img src="https://panda-website-1301093743.cos.ap-hongkong.myqcloud.com/images/logo/panda-thu-logo.png" alt=" "></a>
                    </div>
                </div>
                <!-- logo -->
                <div class="col-md-8 col-sm-8 col-xs-12">
                    <div id="navigation">
                        <!-- navigation start-->
                        <ul>
                            <li class="active"><a href="index.html" class="animsition-link">Home</a></li>
                            <li><a href="#" class="animsition-link">challenges</a><ul>
                                <li><a href="Task1.html">Task1: Object Detection</a></li>
                                <li><a href="Task2.html">Task2: Multi-Object Tracking</a></li>
                            </ul></li>
                            <li><a href="#" class="animsition-link">Evaluate</a><ul>
                                <li><a href="Evaluate1.html">Task1: Object Detection</a></li>
                                <li><a href="Evaluate2.html">Task2: Multi-Object Tracking</a></li>
                            </ul></li>
                            <!-- <li><a href="UnstructuredCam.html" class="animsition-link">UnstructuredCam</a></li>
                            <li><a href="RUSH_Macroscopy.html" class="animsition-link">RUSH Macroscopy</a></li>
                            <li><a href="http://www.gigavision.cn/" class="animsition-link">GigaVision</a></li> -->
                            <li><a href="Download.html" class="animsition-link">Download</a></li>
                            <!-- <li><a href="#" class="animsition-link">Leaderboards</a><ul>
                                <li><a href="#">Task1: Object Detection</a></li>
                                <li><a href="#">Task2: Multi-Object Tracking</a></li>
                            </ul></li> -->
                            <li><a href="FAQ.html" class="animsition-link">FAQ</a></li>
                            <li><a href="Team.html" class="animsition-link">Team</a></li>
                        </ul>
                    </div>
                    <!-- /.navigation start-->
                </div>
            </div>
        </div>
    </div>

    <div class="page-header">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <div class="page-breadcrumb">
                        <ol class="breadcrumb">
                            <li><a href="index.html">Home</a></li>
                            <li><a href="#">challenges</a></li>
                            <li class="active">Task1</li>
                        </ol>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="section-space20 bg-white">
        <!-- content start -->
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <div class="wrapper-content bg-white">
                        <div class="team-section text-justify pinside40">
                            <div class="row">
                                <h1>Task1: Pedestrian & Vehicle Detection</h1>
                                <p><img src="https://panda-website-1301093743.cos.ap-hongkong.myqcloud.com/images/home/info1.jpg" alt="" align="middle" width="110%" /></p>


                                <h2>Part 1: Crowd Counting</h2>
                                <p>This task is intended to evaluate the ability of algorithms to estimate the crowd density map in a complex scenario. For this task, participants will use our Gigapixel Video Dataset, a new resource with high spatial resolution and wide FOV simultaneously for computer vision challenges.</p>
                                <h3>Dataset Download:</h3>
                                <p>The Gigapixel Video Dataset 0.1alpha will be used for this task. This dataset consists of 65 representative images from the train station and the shanghai marathon sequences. These images are saved in JPEG format with more than 200K heads. We will release more labeled data in the future.</p>
                                <ul>
                                    <li>Stitched Images and human head labels: <a href="https://hkustconnect-my.sharepoint.com/:f:/g/personal/xyuanag_connect_ust_hk/EnfTCLlyP99KvEVtM9rOXPQBKM1dei-4dDHwaZ4GdrbyeA?e=cpeDhe">download here</a></li>
                                    <li>Unlabeled video sequences: <a href="https://hkustconnect-my.sharepoint.com/:f:/g/personal/xyuanag_connect_ust_hk/EqAodAmiq3lJhcU5jleSlroBTWhg-ssHatuNF12FLcKC-g?e=w7A6ag">download here</a></li>
                                </ul>
                                <div class="section-space20 pinside20 bg-primary">
                                    <h4>Invalid Area</h4>
                                    <p>Limited by the resolution, sometimes even human can not clearly count the exact number of people in some far places. Therefore, we have delineated some invalid areas which are considered artificially unrecognizable and have no groundtruth label.</p>
                                    <table border="1" width="80%" align="center">
                                        <tbody align="center">
                                            <tr>
                                                <td>Dataset</td>
                                                <td>Image Size</td>
                                                <td>Invalid Area</td>
                                            </tr>
                                            <tr>
                                                <td>shanghai_marathon</td>
                                                <td>26908 × 15024</td>
                                                <td>1 ≤ x ≤ 26908, 1 ≤ y ≤ 6670</td>
                                            </tr>
                                            <tr>
                                                <td>train_station</td>
                                                <td>26558 × 14828</td>
                                                <td>1 ≤ x ≤ 26558, 1 ≤ y ≤ 5130</td>
                                             </tr>
                                        </tbody>
                                    </table>
                                    <p>Note: The top left pixel is set to the origin of the coordinates (x = 1, y = 1).</p>
                                </div>
                                <h3>Format:</h3>
                                <p>The groundtruth labels are saved in .mat and .txt files. The first two lines indicate the total number of people in the image. After that, each line represents a head position. The first number is the x coordinate; the second number is the y coordinate. The top left pixel is (1,1).</p>
                                <div class="section-space20 pinside20 bg-primary">
                                    <p>\#number</br>
                                     &lt;num_points&gt;</br>
                                    \#position</br>
                                    &lt;x1 y1&gt;</br>
                                    &lt;x2 y2&gt;</br>
                                    ...</br>
                                    &lt;xN yN&gt;
                                    </p>
                               </div>
                                <p>Deep learning based computer vision algorithms have surpassed the human-level performance for many CV tasks, like object recognition and face verification. Object detection is a fundamental task for human-centric visual analysis. The extremely high resolution of PANDA makes it possible to detect objects from a long distance. However, the significant variance in scale, posture, and occlusion severely degrade the detection performance.</p>
                                
                               <p>This task is designed to push the state-of-the-art in object detection on giga-pixel images forward. Teams are required to predict the bounding boxes of objects of pedestrians and vehicles with real-valued confidences. Some special regions (e.g., fake persons, extremely crowded regions, heavily occluded persons, etc.) are ignored in evaluation. </p>

                               <p>There will be 2 tracks: pedestrian detection and vehicle detection. For pedestrian detection track, There will be 3 sub-tasks: visible body, full body, and head detection for pedestrians. </p>

                               <p>The challenge is based on PANDA-Image dataset which contains 555 static giga-pixel images (390 for training, 165 for testing) captured by giga-pixel camera in different places at different height. We manually annotate the bounding boxes of different categories of objects in each image. Specifically, each person is annotated by 3 box, visible body box, full body box, and head box. It is worth mentioning that a target is skipped during evaluation if its IoU with special regions is larger than 0.5. All data and annotations on the training set are publicly available.</p>

                               <h3>Challenge Guidelines</h3>
                               <p>The object detection evaluation page lists detailed information regarding how submissions will be scored. To limit overfitting while providing researchers more flexibility to test their algorithms, we have divided the test set into two splits, including test-challenge and test-dev. Test-dev (60 images) is designed for debugging and validation experiments and allows for unlimited submission. The up-to-date results of the test-dev set are available to view on the leaderboard.</p>
                               <p>We encourage the participants to use the provided training data, while also allow them to use additional training data. The use of external data must be indicated during submission.</p>
                               <p>The train set images and corresponding annotations are available on the download page. The submitted results will be evaluated according to the rules described on the evaluation page. Please refer to the  evaluation page for detailed explanation.</p>
                               <h3>Tools and Instructions</h3>
                               <p>We provide extensive API support for the PANDA images, annotation and evaluation code. Please visit our GitHub repository to download the PANDA API. For addition questions, please find the answers in FAQ or contact us.</p>

                               <h2>Citation</h2>
                               <p>When using our datasets in your research, please cite:</p>
                                <p>
                                    @inproceedings{yuan2017multiscale,<br>
                                        title={Multiscale gigapixel video: A cross resolution image matching and warping approach},<br>
                                        author={Yuan, Xiaoyun and Fang, Lu and Dai, Qionghai and Brady, David J and Liu, Yebin},<br>
                                        booktitle={Computational Photography (ICCP), 2017 IEEE International Conference on},<br>
                                        pages={1--9},<br>
                                        year={2017},<br>
                                        organization={IEEE}<br>
                                        }
                                </p>
                                <h2>Privacy</h2>
                                <p>This dataset is for non-commercial use only. However, if you find yourself or your personal belongings in the data, please <a href="malito:zhang-xy18@mails.tsinghua.edu.cn">contact us</a>, and we will immediately remove the respective images from our servers.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- /.content end -->
    
    <div class="footer section-space20">
        <!-- footer -->
        <div class="container">
            <div class="row">
                <div class="col-md-4 col-sm-4 col-xs-6">
                    <div class="widget-footer">
                        <!-- widget footer -->
                        <ul class="listnone">
                            <li><a href="http://www.gigavision.cn">GigaVision</a></li>
                            <li><a href="http://cvpr2019.thecvf.com/">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019</a></li>
                            <li><a href="https://eccv2020.eu/">The 2020 European Conference on Computer Vision (ECCV 2020)</a></li>
                        </ul>
                    </div>
                    <!-- /.widget footer -->
                </div>
                <div class="col-md-4 col-sm-4 col-xs-6">
                    <div class="widget-footer">
                        <!-- widget footer -->
                        <ul class="listnone">
                            <li><a href="http://www.luvision.net/">Smart Imaging Laboratory</a></li>
                            <li>Email: <a href="mailto:zhang-xy18@mails.tsinghua.edu.cn">zhang-xy18@mails.tsinghua.edu.cn</a></li>
                            <li>Postal addresses: Room 607, C2 building, Nanshanzhiyuan. Park, Xueyuan Ave. Num. 1001, Nanshan District, Shenzhen, China.</li>
                        </ul>
                    </div>
                    <!-- /.widget footer -->
                </div>
                <div class="col-md-4 col-sm-4 col-xs-6">
                    <div class="widget-footer">
                        <!-- widget footer -->
                        <ul class="listnone">
                            <li><p>This work is supported in part by Natural Science Foundation of China (NSFC) under contract No. 61722209 and 61860206003.</p></li>
                            <li><p>We thank <a href="http://www.cvcam.cn/">Beijing Zhuohe Technology Co., Ltd.</a> for providing part of raw datasets.</p></li>
                        </ul>
                    </div>
                    <!-- /.widget footer -->
                </div>
            </div>
        </div>
    </div>
    <!-- /.footer -->
    <div class="tiny-footer">
        <!-- tiny footer -->
        <div class="container">
            <div class="row text-center">
                <div class="col-md-12 col-sm-12 col-xs-12">
                    <p>Industry-University-Research Collaboration is welcome via E-mail: fanglu at sz.tsinghua.edu.cn</br>
                    Smart Imaging Lab, TBSI, Tsinghua University&nbsp;&nbsp;&nbsp;&nbsp;Copyright &copy; 2020 All rights reserved</p>
                </div>
            </div>
        </div>
    </div>
    <!-- /.tiny footer -->
    <!-- back to top icon -->
    <a href="#0" class="cd-top" title="Go to top">Top</a>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
    <script type="text/javascript" src="js/menumaker.js"></script>
    <!-- animsition -->
    <script type="text/javascript" src="js/animsition.js"></script>
    <script type="text/javascript" src="js/animsition-script.js"></script>
    <!-- sticky header -->
    <script type="text/javascript" src="js/jquery.sticky.js"></script>
    <script type="text/javascript" src="js/sticky-header.js"></script>
    <!-- slider script -->
    <script type="text/javascript" src="js/owl.carousel.min.js"></script>
    <script type="text/javascript" src="js/slider-carousel.js"></script>
    <script type="text/javascript" src="js/service-carousel.js"></script>
    <!-- Back to top script -->
    <script src="js/back-to-top.js" type="text/javascript"></script>
</body>

</html>

